# Introduction to Distributed Systems
> Distributed systems is art of solving the same problem youc an solve on a single computer, using multiple computers.

> There is a continuous tension between the reality that there are multiple nodes and our desire for it to behave like a single system. These models are often very expensive in DS, even the most common models of shared memory abstraction is very expensive too.

A computer needs to perform 2 basic tasks
* Computation/Processing
* Storage

**Nothing ever demands you use distributed systems, given infinite research time and money you'd probably end up not needing distributed systems.**

There are two types of single node computers.
* High end computing devices
* Low end computing devices

You only benefit from high eng computing devices as long as the network accesses are replaces by in memory accesses. If not, the high end computing would also keep on wasting it's computing resources waiting on I/O from internet.

### Aspects of Distributed Systems
* [Scalability](#scalability)
* [Availability](#availability)
* [Guarantees](#guarantees)
**The best value is in the mig-range commodity hardware, as long as the maintenance cost can be kept down using fault tolerant systems.**

### Scalability-
* Size Scalability- Adding more nodes should make the system linearly faster. Growing dataset size shouldn't increase latency.
* Admin Scalability- Adding more nodes shouldn't make lives of admins hard.

#### Performance
It's usually the amount of useful work done by the system in ratio to the resources used by it.
This, in different contexts might mean different things-
* Low Latency. (When your api is usually customer facing.)
* High Throughput. (In batch cases, it's really high, though individual latencies go for a toss.)
* Low utilization of computing resources. (When you wanna save on infra \$\$ )

**The system that doesn't change doesn't have a latency problem.**

There is min latency(speed of light), and components latencies as well incurred per operation. (HDDs,SSDs,RAMs,CPUs)

### Availability
Portion of time a system is in desired functioning condition. DSs take up a bunch of unreliable components and make up a reliable system.
$$ Availability={ uptime \over uptime+downtime} $$

Availability is all about being fault tolerant. You can increase availability by adding more components, but more components mean more faults. (You have to tolerate them, and keep the admin cost minimum)

So, more the nodes, more the faults, more the admin costs usually.
more the distance between nodes, more the minimum latency for communication.

### Guarantees
Another very important aspect is how understandable are the guarantees that are made.

**Error= incorrect behaviour**

**Anomaly= unexpected behaviour**

There are typically 3 modes
* System Mode= sync/async
* Failure Mode= crash/fail, partitions, byzantine
* Consitency= strong/eventual

**System that makes weaker guarantees has more freedom of action and hence potentially greater performance but potentially harder to reason about as well.**

### Design Techniques

#### Partitioning
* Improves performance by limiting the amount of data to be examined and by locating the related data in the same partition.
* Partitions can fail independently, the bus factor for the nodes increases before availability goes for a toss.

#### Replication
**The cause of and solution to all of life's problems.**
* Improves performance.
* Improves availability.

* !! Replicas need to be kept in sync